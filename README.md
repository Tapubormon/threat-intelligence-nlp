# Reddit CTI Relevance Classifier & IOC Extraction

A machine learning pipeline for collecting Reddit posts, classifying Cyber Threat Intelligence (CTI) relevance, and extracting/validating Indicators of Compromise (IOCs).

## Quick Start

### Phase 1: Model Training

#### Step 1-3: Collect & Preprocess Data

1. **Setup Configuration**
   - Copy `config/reddit_config.py.example` to `config/reddit_config.py`
   - Add your Reddit API credentials

2. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Collect & Preprocess Data**
   ```bash
   python scripts/reddit_collector.py      # â†’ reddit_raw_data.json
   python scripts/preprocessor.py          # â†’ reddit_clean_data.json
   python scripts/csv_conversion.py        # â†’ reddit_ml_ready.csv
   ```
   
   **Note**: If `reddit_collector.py` fails, the system automatically runs:
   - `fallback_scraper.py` â†’ merges with `top_domain.py` â†’ `enrich_posts.py`

#### Step 4: Label Data - Choose One Option

##### Option A: Automatic Labeling (Quick - for testing)
```bash
python scripts/label_data.py             # â†’ reddit_ml_ready_labeled.csv
```
- âš¡ Fast labeling using keyword-based matching
- âš ï¸ Not 100% accurate - uses heuristics and patterns
- âœ… Good for testing, prototyping, or reducing time
- ğŸ“ **Note**: Review results and verify manually before production use

##### Option B: Manual Labeling (Accurate - for production)
1. Open `scripts/data/reddit_ml_ready.csv` in your preferred tool (Excel, Google Sheets, etc.)
2. Label each post as CTI-relevant or non-relevant
3. Save as `reddit_ml_ready_labeled.csv` in `scripts/data/`
- âœ… High accuracy - human verification
- â±ï¸ Takes more time
- ğŸ¯ Recommended for production models

#### Step 5-6: Train Model

5. **Upload Labeled Data**
   - Upload `reddit_ml_ready_labeled.csv` to Google Drive

6. **Train Model**
   - Run all cells in `CTI_Relevance_Classifier.ipynb` in Google Colab
   - Model saves automatically to Google Drive under `distilbert_cti_model/` folder

âœ… **Model training complete**

---

### Phase 2: Predict on New Data

#### Step 7-10: Collect & Preprocess New Data

7. **Collect New Posts**
   ```bash
   python scripts/reddit_collector.py      # â†’ reddit_raw_data.json
   ```

8. **Preprocess Data**
   ```bash
   python scripts/light_preprocessor.py          # â†’ reddit_clean_data_light.json
   ```

9. **Convert to CSV**
   ```bash
   python scripts/csv_conversion.py        # â†’ reddit_ml_ready.csv
   ```

10. **Upload to Google Drive**
    - Upload `reddit_ml_ready.csv` to Google Drive

#### Step 11-13: Classify & Extract IOCs

11. **Classify Posts**
    - Run all cells in `CTI_Relevance_Classifier_with_new_data.ipynb`
    - Output: `relevant_posts.csv`

12. **Extract IOCs**
    - Run all cells in `IOC_Extraction_ipynp.ipynb`
    - Output: `extracted_iocs.json`

13. **Validate IOCs**
    - Run all cells in `Check_With_Virus_tools.ipynb`
    - Output: `validated_iocs.json`

## Project Structure

```
project-root/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ reddit_config.py.example
â”‚   â””â”€â”€ reddit_config.py (local - not uploaded)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ reddit_collector.py
â”‚   â”œâ”€â”€ fallback_scraper.py
â”‚   â”œâ”€â”€ preprocessor.py
â”‚   â”œâ”€â”€ csv_conversion.py
â”‚   â”œâ”€â”€ label_data.py           â† Auto-labeling (optional)
â”‚   â”œâ”€â”€ enrich_posts.py
â”‚   â”œâ”€â”€ top_domain.py
â”‚   â”œâ”€â”€ checkLength.py
â”‚   â”œâ”€â”€ scheduler.py
â”‚   â””â”€â”€ data/ (local - not uploaded)
â”œâ”€â”€ CTI_Relevance_Classifier.ipynb
â”œâ”€â”€ CTI_Relevance_Classifier_with_new_data.ipynb
â”œâ”€â”€ IOC_Extraction_ipynp.ipynb
â”œâ”€â”€ Check_With_Virus_tools.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Requirements

- Python 3.8+
- Reddit API credentials
- Google Drive account (for model storage)
- VirusTotal API key (optional, for IOC validation)

See `requirements.txt` for Python dependencies.


